{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "location = \"D:\\\\Training_Data_SVM_Control\\\\\"\n",
    "\n",
    "\n",
    "imageList = []\n",
    "labelList = []\n",
    "ytrain = []\n",
    "\n",
    "for dirName, x, fileList in os.walk(location):\n",
    "    \n",
    "    for filename in fileList:\n",
    "        if(filename[-4:] == \".jpg\" and not filename[-7:] == \"ged.jpg\"):\n",
    "            \n",
    "            json_file_location = os.path.join(dirName, filename[:-4] + \".json\")\n",
    "            \n",
    "            if os.path.exists(json_file_location):\n",
    "                \n",
    "                jpg_file_location = os.path.join(dirName, filename)\n",
    "                imageList.append(str(jpg_file_location))\n",
    "                labelList.append(str(json_file_location))\n",
    "\n",
    "for json_file in labelList:\n",
    "    file = open(json_file)\n",
    "    data = json.load(file)\n",
    "    ytrain.append(data[\"Pano_Data\"][0][\"label_type\"])\n",
    "\n",
    "    \n",
    "    \n",
    "X = np.array([np.array(Image.open(fname)) for fname in imageList])    \n",
    "y = np.array(ytrain,)\n",
    "\n",
    "y = y.reshape(y.shape[0],)\n",
    "image_features = X.reshape(X.shape[1] * X.shape[2] * X.shape[3], X.shape[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting null Data too\n",
    "\n",
    "null_location = \"D:\\\\Training_Data_SVM_null\\\\\"\n",
    "null_img_list = []\n",
    "null_y_train = []\n",
    "for dirName, x, fileList in os.walk(null_location):\n",
    "    for filename in fileList:\n",
    "        if(filename[-4:] == \".jpg\" and not filename[-7:] == \"ged.jpg\" and not filename[0] == '.'):\n",
    "            null_jpg_location = os.path.join(dirName, filename)\n",
    "            null_img_list.append(null_jpg_location)\n",
    "            null_y_train.append(\"null\")\n",
    "            \n",
    "null_y_train = np.array(null_y_train).reshape(len(null_y_train),)\n",
    "\n",
    "null_img_list = np.array([np.array(Image.open(fname)) for fname in null_img_list])\n",
    "null_img_list = null_img_list.reshape(null_img_list.shape[1] * null_img_list.shape[2] * null_img_list.shape[3], null_img_list.shape[0]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2511, 181548)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_set = np.concatenate((image_features, null_img_list) , 0)\n",
    "new_y = np.concatenate((y, null_y_train), 0)\n",
    "new_feature_set.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sift_dict(image_list, n_classes, sift):\n",
    "    sift_descriptors = []\n",
    "    \n",
    "    \n",
    "    for image_path in image_list:\n",
    "        img = cv2.imread(image_path)\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "        print(image_path, end = '\\r')\n",
    "        for d in des:\n",
    "            sift_descriptors.append(d)\n",
    "    k = 10 * n_classes\n",
    "    batch_size = np.size(len(image_list)) * 3\n",
    "    \n",
    "    kmeans = MiniBatchKMeans(n_clusters = k, batch_size = batch_size, verbose = 1).fit(sift_descriptors)\n",
    "    kmeans.verbose = False\n",
    "    \n",
    "    return kmeans\n",
    "\n",
    "def get_sift_features(n_classes,image_list, feature_dict, sift):\n",
    "    histo_list = []\n",
    "\n",
    "    for img_path in image_list:\n",
    "        img = cv2.imread(img_path)\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "        k = 10 * n_classes\n",
    "        histo = np.zeros(k)\n",
    "        nkp = np.size(kp)\n",
    "\n",
    "        for d in des:\n",
    "            idx = feature_dict.predict([d])\n",
    "            histo[idx] += 1/nkp\n",
    "\n",
    "        histo_list.append(histo)\n",
    "    return np.array(histo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/3 with method: k-means++stacle\\8q\\8qql7NbVqcC_EnaW43WeCw_._Obstacle_._2842.890758547011_._1228.923076923077_._.jpggg.jpg_._.jpgg\n",
      "Inertia for init 1/3: 0.000000\n",
      "Init 2/3 with method: k-means++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubicomp\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:1418: RuntimeWarning: init_size=9 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia for init 2/3: 0.000000\n",
      "Init 3/3 with method: k-means++\n",
      "Inertia for init 3/3: 0.000000\n",
      "Minibatch iteration 1/22320500: mean batch inertia: 87096.333333, ewa inertia: 87096.333333 \n",
      "Minibatch iteration 2/22320500: mean batch inertia: 92712.333333, ewa inertia: 87096.383655 \n",
      "Minibatch iteration 3/22320500: mean batch inertia: 88152.666667, ewa inertia: 87096.393119 \n",
      "Minibatch iteration 4/22320500: mean batch inertia: 103660.333333, ewa inertia: 87096.541538 \n",
      "Minibatch iteration 5/22320500: mean batch inertia: 122824.666667, ewa inertia: 87096.861675 \n",
      "Minibatch iteration 6/22320500: mean batch inertia: 63560.000000, ewa inertia: 87096.650776 \n",
      "Minibatch iteration 7/22320500: mean batch inertia: 106429.333333, ewa inertia: 87096.824004 \n",
      "Minibatch iteration 8/22320500: mean batch inertia: 41229.666667, ewa inertia: 87096.413018 \n",
      "Minibatch iteration 9/22320500: mean batch inertia: 118722.000000, ewa inertia: 87096.696395 \n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Minibatch iteration 10/22320500: mean batch inertia: 92941.333333, ewa inertia: 87096.748765 \n",
      "Minibatch iteration 11/22320500: mean batch inertia: 92770.333333, ewa inertia: 87096.799602 \n",
      "Converged (lack of improvement in inertia) at iteration 11/22320500\n",
      "Computing label assignment and total inertia\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "sift_dict = get_sift_dict(imageList, 50, sift)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_features = get_sift_features(50,imageList, sift_dict, sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1998, 500)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sift_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X = sift_features\n",
    "y = y.reshape(y.shape[0],)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_features, y, test_size = 0.05, random_state = 400)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0  0]\n",
      " [ 0 22  0  0]\n",
      " [ 0  0 24  0]\n",
      " [ 0  0  0 29]]\n",
      "Accurancy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"Accurancy:\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239   0   0   0]\n",
      " [276   0   0   0]\n",
      " [245   0   0   0]\n",
      " [239   0   0   0]]\n",
      "0.23923923923923923\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.metrics.confusion_matrix(y_test, preds))\n",
    "print(sklearn.metrics.accuracy_score(y_test ,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train == \"SurfaceProblem\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis(clf, X_test, y_test):\n",
    "    preds = clf.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    print(\"Accurancy:\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[113   0   0   0   0]\n",
      " [  0  99   0   0   0]\n",
      " [  0   0  84   0   0]\n",
      " [  0   0   0  96   0]\n",
      " [  0   0   0   0 111]]\n",
      "Accurancy: 1.0\n",
      "[[ 96   0   0   0   0]\n",
      " [  0 100   0   0   0]\n",
      " [  0   1  91   0   0]\n",
      " [  0   0   0  99   0]\n",
      " [  0   0   0   0 115]]\n",
      "Accurancy: 0.99800796812749\n",
      "[[ 88   0   0   0   0]\n",
      " [  0  99   0   1   0]\n",
      " [  0   0 100   0   0]\n",
      " [  0   0   0 111   0]\n",
      " [  0   0   0   0 103]]\n",
      "Accurancy: 0.99800796812749\n",
      "[[ 87   0   0   0   0]\n",
      " [  0 102   0   0   0]\n",
      " [  0   0 109   0   0]\n",
      " [  0   0   0 106   0]\n",
      " [  0   0   0   0  98]]\n",
      "Accurancy: 1.0\n",
      "[[117   0   0   0   0]\n",
      " [  0 100   0   0   0]\n",
      " [  0   1 113   0   0]\n",
      " [  0   0   0  85   0]\n",
      " [  0   0   0   0  86]]\n",
      "Accurancy: 0.99800796812749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "number_of_folds = 5\n",
    "randomize = True\n",
    "\n",
    "kfold = KFold(number_of_folds, randomize, 4)\n",
    "\n",
    "for train, test in kfold.split(new_feature_set):\n",
    "    X_train = new_feature_set[train]\n",
    "    X_test = new_feature_set[test]\n",
    "    \n",
    "    y_train = new_y[train]\n",
    "    y_test = new_y[test]\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    data_analysis(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "pano_test_path = \"D:\\Pano_4096_2048\\ZT\\zt1knLZN3ZW2ROPCkMjyJg_4096_2048.jpg\"\n",
    "\n",
    "pano = np.array(Image.open(pano_test_path))\n",
    "\n",
    "print(pano.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 99, 3)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pano[1:100, 1:100,:]\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
